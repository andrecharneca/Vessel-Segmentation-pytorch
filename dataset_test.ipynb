{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import pkbar\n",
    "from unet3d.config import *\n",
    "from utils.Visualization import ImageSliceViewer3D\n",
    "from tqdm import tqdm\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import glob\n",
    "from torch.optim import Adam\n",
    "from unet3d.dataset import SAIADDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from patchify import patchify\n",
    "from utils.Other import get_headers\n",
    "import nrrd\n",
    "from unet3d.transforms import train_transform_cuda\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "_,_,patient_names = get_headers(DATASET_PATH)\n",
    "device = 'cuda'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with val patients: ['SAIAD 15', 'SAIAD 11']\n",
      "Fetching patients probabilities...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:06<00:00,  2.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching patients probabilities...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  2.37it/s]\n",
      "/Work/Users/acharneca/.conda/envs/saiad-pytorch/lib/python3.8/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "from unet3d.dataset import WrappedDataLoader, to_device\n",
    "\n",
    "\n",
    "excl_patients_training = ['SAIAD 15', 'SAIAD 11'] #patients for validation/testing\n",
    "excl_patients_val = list(set(patient_names) - set(excl_patients_training))\n",
    "\n",
    "print(\"Training with val patients:\", excl_patients_training)\n",
    "\n",
    "\n",
    "\n",
    "## Load dataset ##\n",
    "train_dataset = SAIADDataset(\n",
    "    excl_patients=excl_patients_training,\n",
    "    load_data_to_memory=True,\n",
    "    n_batches=TRAIN_BATCHES_PER_EPOCH,\n",
    "    transform=None,\n",
    "    non_unif_sampling=True\n",
    "    )\n",
    "val_dataset = SAIADDataset(\n",
    "    excl_patients=excl_patients_val,\n",
    "    load_data_to_memory=True,\n",
    "    n_batches=VAL_BATCHES_PER_EPOCH,\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=TRAIN_BATCH_SIZE,\n",
    "    shuffle=False, \n",
    "    pin_memory=False, \n",
    "    num_workers=NUM_WORKERS\n",
    "    )\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=VAL_BATCH_SIZE,\n",
    "    shuffle=False, \n",
    "    pin_memory=False, \n",
    "    num_workers=NUM_WORKERS\n",
    "    )\n",
    "\n",
    "train_dataloader = WrappedDataLoader(train_dataloader, to_device, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/150 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/Work/Users/acharneca/.conda/envs/saiad-pytorch/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 302, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/Work/Users/acharneca/.conda/envs/saiad-pytorch/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/Work/Users/acharneca/.conda/envs/saiad-pytorch/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/Work/Users/acharneca/Vessel-Segmentation-pytorch/unet3d/dataset.py\", line 215, in __getitem__\n    patch_scan, patch_segm = self.__get_patches_from_patient(patient_idx.item())\n  File \"/Work/Users/acharneca/Vessel-Segmentation-pytorch/unet3d/dataset.py\", line 206, in __get_patches_from_patient\n    patch_segm = one_hot(patch_segm, num_classes=self.n_classes).permute(3,0,1,2)\nRuntimeError: one_hot is only applicable to index tensor.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(EPOCHS)):\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m X_batch, y_batch \u001b[38;5;129;01min\u001b[39;00m train_dataloader:\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/Vessel-Segmentation-pytorch/unet3d/dataset.py:237\u001b[0m, in \u001b[0;36mWrappedDataLoader.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    236\u001b[0m     batches \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdl)\n\u001b[0;32m--> 237\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m batches:\n\u001b[1;32m    238\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(\u001b[38;5;241m*\u001b[39mb, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs))\n",
      "File \u001b[0;32m~/.conda/envs/saiad-pytorch/lib/python3.8/site-packages/torch/utils/data/dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 681\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    684\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    685\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.conda/envs/saiad-pytorch/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1376\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1374\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1375\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1376\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/saiad-pytorch/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1402\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1400\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1402\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1403\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/.conda/envs/saiad-pytorch/lib/python3.8/site-packages/torch/_utils.py:461\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    458\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    459\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m--> 461\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/Work/Users/acharneca/.conda/envs/saiad-pytorch/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 302, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/Work/Users/acharneca/.conda/envs/saiad-pytorch/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/Work/Users/acharneca/.conda/envs/saiad-pytorch/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/Work/Users/acharneca/Vessel-Segmentation-pytorch/unet3d/dataset.py\", line 215, in __getitem__\n    patch_scan, patch_segm = self.__get_patches_from_patient(patient_idx.item())\n  File \"/Work/Users/acharneca/Vessel-Segmentation-pytorch/unet3d/dataset.py\", line 206, in __get_patches_from_patient\n    patch_segm = one_hot(patch_segm, num_classes=self.n_classes).permute(3,0,1,2)\nRuntimeError: one_hot is only applicable to index tensor.\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    for X_batch, y_batch in train_dataloader:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading w/ transforms: 25s/epoch\n",
    "\n",
    "Loading w/o transforms: 23s/epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([8, 1, 96, 96, 96]), torch.float16, device(type='cuda', index=0)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[y_batch.shape, y_batch.dtype, y_batch.device]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f765de65b3354fe6a44bb325fe369be4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(RadioButtons(description='Slice plane selection:', options=('x-y', 'y-z', 'z-x'), style=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<utils.Visualization.ImageSliceViewer3D at 0x16e55e400>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n=0\n",
    "ImageSliceViewer3D(np.array(patch_scan[0]), np.array(torch.argmax(patch_segm, dim=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4199c044ae064949a51c63b527a18371",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(RadioButtons(description='Slice plane selection:', options=('x-y', 'y-z', 'z-x'), style=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<utils.Visualization.ImageSliceViewer3D at 0x17ab64f70>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from monai.transforms import Compose, RandFlipd, ToTensord, RandGaussianNoised, RandAdjustContrastd\n",
    "patchs = {'name': 'patches', 'patch_scan': patch_scan, 'patch_segm': patch_segm}\n",
    "transform = Compose(\n",
    "    [   \n",
    "        RandFlipd(keys=['patch_scan', 'patch_segm'], prob=1, spatial_axis=0),\n",
    "        RandGaussianNoised(keys=['patch_scan', 'patch_segm'], prob=1, mean=0.0, std=0.1),\n",
    "        RandAdjustContrastd(keys=['patch_scan', 'patch_segm'], prob=1, gamma=(0.5,2)),\n",
    "        ToTensord(keys=['patch_scan', 'patch_segm'], device='mps')\n",
    "    ]\n",
    ")\n",
    "trans_patchs = transform(patchs)\n",
    "ImageSliceViewer3D(np.array(trans_patchs['patch_scan'].cpu()[0]), np.array(patch_scan[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(255.)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patch_scan.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "32aad0a8508bff835c20a8d47234734688fb62c0cbdf7488c1eae1822cd413fe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
