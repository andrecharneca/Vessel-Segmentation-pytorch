{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b50ad5fb-056c-498a-8e7d-be00a431def8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "/Work/Users/acharneca/Vessel-Segmentation-pytorch/checkpoints/saiad1and13_epoch149_23sep.pth\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import pkbar\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "from torchsummary import summary\n",
    "from torch.nn.functional import one_hot\n",
    "from unet3d.config import *\n",
    "from unet3d.tester import Tester\n",
    "from unet3d.dice import dice_coef_torch_multiclass\n",
    "from unet3d.transforms import *\n",
    "from unet3d.unet3d_vgg16 import UNet3D_VGG16\n",
    "from unet3d.transforms import val_transform\n",
    "from utils.Visualization import ImageSliceViewer3D\n",
    "import nrrd\n",
    "from patchify import patchify, unpatchify\n",
    "import os \n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.benchmark = True # Speeds up stuff\n",
    "torch.backends.cudnn.enabled = True\n",
    "device = torch.device('cuda')\n",
    "\n",
    "model_path = 'checkpoints/saiad1and13_epoch149_23sep.pth'\n",
    "model_path = os.path.realpath(model_path)\n",
    "print(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "687bc0af-104d-48ce-8900-c89281409e80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(528, 528, 144)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tester = Tester(\n",
    "    model_path, \n",
    "    test_patient = 'SAIAD 1'\n",
    "    )\n",
    "\n",
    "tester.read_test_patient_data_and_pad()\n",
    "tester.scan.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5be43ef6-025f-4c79-8ca2-fcb9bff21dbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10, 2, 96, 96, 96)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scan_patchified = tester.patchify_scan()\n",
    "scan_patchified.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e16fd9b-71f3-49a9-a2ad-2beca31bf8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch = np.array([scan_patchified[5,5,1]])\n",
    "patch_transform = {'patch_scan': patch, \n",
    "                   'patch_scan_flipped': patch,\n",
    "                   'patch_scan_noise': patch, \n",
    "                   'patch_scan_contrast': patch\n",
    "                  }\n",
    "patch_transform = test_transform(patch_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe91cf46-92b1-4e3a-9430-e35e1501aa9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c61113de20874e90b3fbabe3e453ef7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(RadioButtons(description='Slice plane selection:', options=('x-y', 'y-z', 'z-x'), style=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<utils.Visualization.ImageSliceViewer3D at 0x1468d78143a0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ImageSliceViewer3D(patch_transform['patch_scan'][0],patch_transform['patch_scan_contrast'][0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "857d38d2-8a65-4bd5-9be1-0aafa262950d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patchifying scan...\n",
      "(10, 10, 2, 5, 96, 96, 96)\n",
      "Predicting on patches...\n",
      "(10, 10, 2, 96, 96, 96, 5)\n",
      "Unpatchifying...\n",
      "(528, 528, 144, 5)\n",
      "(528, 528, 144)\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "temp = tester.predict(with_transforms=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cfe0dbe9-7f31-4d66-b9d3-2eced85ea2aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96, 96, 96)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "033637dbe479439ea8183c90a78dcd31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(RadioButtons(description='Slice plane selection:', options=('x-y', 'y-z', 'z-x'), style=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<utils.Visualization.ImageSliceViewer3D at 0x1468d705fac0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol = temp['single_patch_predictions'].cpu().detach().numpy()[1,3]#[5,5,1,:,:,:,0]\n",
    "print(vol.shape)\n",
    "ImageSliceViewer3D(patch_transform['patch_scan'][0], vol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d8bbb51a-e2c6-47b3-91bf-815084a5844d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b91bdac2bfa445c4805e87079cfbda23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(RadioButtons(description='Slice plane selection:', options=('x-y', 'y-z', 'z-x'), style=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tester.show_truth_vs_pred()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe5f07a-b83e-403f-abde-d03b33497772",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b712c0d3-d6a1-4522-9df6-fe63b81e600c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNet3D_VGG16(\n",
       "  (encoder_block1): Conv3DBlock_2conv(\n",
       "    (conv1): Conv3d(1, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=same)\n",
       "    (relu): ReLU()\n",
       "    (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=same)\n",
       "    (pooling): MaxPool3d(kernel_size=(2, 2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (encoder_block2): Conv3DBlock_2conv(\n",
       "    (conv1): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=same)\n",
       "    (relu): ReLU()\n",
       "    (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=same)\n",
       "    (pooling): MaxPool3d(kernel_size=(2, 2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (encoder_block3): Conv3DBlock_3conv(\n",
       "    (conv1): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=same)\n",
       "    (relu): ReLU()\n",
       "    (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=same)\n",
       "    (pooling): MaxPool3d(kernel_size=(2, 2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (encoder_block4): Conv3DBlock_3conv(\n",
       "    (conv1): Conv3d(256, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=same)\n",
       "    (relu): ReLU()\n",
       "    (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=same)\n",
       "    (pooling): MaxPool3d(kernel_size=(2, 2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (encoder_block5): Conv3DBlock_3conv(\n",
       "    (conv1): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=same)\n",
       "    (relu): ReLU()\n",
       "    (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=same)\n",
       "    (pooling): MaxPool3d(kernel_size=(2, 2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (center_block1): Conv3DBlock_center(\n",
       "    (conv): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=same, bias=False)\n",
       "    (bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (center_block2): Conv3DBlock_center(\n",
       "    (conv): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=same, bias=False)\n",
       "    (bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (decoder_block5): UpConv3DBlock(\n",
       "    (upconv): Upsample(scale_factor=2.0, mode=nearest)\n",
       "    (conv1): Conv3d(1024, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=same, bias=False)\n",
       "    (relu): ReLU()\n",
       "    (bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=same, bias=False)\n",
       "  )\n",
       "  (decoder_block4): UpConv3DBlock(\n",
       "    (upconv): Upsample(scale_factor=2.0, mode=nearest)\n",
       "    (conv1): Conv3d(768, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=same, bias=False)\n",
       "    (relu): ReLU()\n",
       "    (bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=same, bias=False)\n",
       "  )\n",
       "  (decoder_block3): UpConv3DBlock(\n",
       "    (upconv): Upsample(scale_factor=2.0, mode=nearest)\n",
       "    (conv1): Conv3d(384, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=same, bias=False)\n",
       "    (relu): ReLU()\n",
       "    (bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=same, bias=False)\n",
       "  )\n",
       "  (decoder_block2): UpConv3DBlock(\n",
       "    (upconv): Upsample(scale_factor=2.0, mode=nearest)\n",
       "    (conv1): Conv3d(192, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=same, bias=False)\n",
       "    (relu): ReLU()\n",
       "    (bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=same, bias=False)\n",
       "  )\n",
       "  (decoder_block1): UpConv3DBlock(\n",
       "    (upconv): Upsample(scale_factor=2.0, mode=nearest)\n",
       "    (conv1): Conv3d(32, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=same, bias=False)\n",
       "    (relu): ReLU()\n",
       "    (bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=same, bias=False)\n",
       "  )\n",
       "  (final_block): FinalBlock(\n",
       "    (conv): Conv3d(16, 5, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=same)\n",
       "    (softmax): Softmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = 'checkpoints/test_epoch149_19sep.pth'\n",
    "model = UNet3D_VGG16(\n",
    "    in_channels=IN_CHANNELS , \n",
    "    num_classes=NUM_CLASSES,\n",
    "    use_softmax_end=True\n",
    "    ).to(device)\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55c2a1cf-2cfb-4f23-92c1-143e425fc9ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.Size([72, 1, 96, 96, 96]), torch.float32]\n",
      "[torch.Size([72, 5, 96, 96, 96]), torch.float32]\n"
     ]
    }
   ],
   "source": [
    "# Test on 1 scan\n",
    "scan, _ = nrrd.read(DATASET_PATH + '/SAIAD 15/scan.nrrd')\n",
    "segm, _ = nrrd.read(DATASET_PATH + '/SAIAD 15/segm.nrrd')\n",
    "scan = np.pad(scan, ((32,32),(32,32),(0,0)), constant_values=0)\n",
    "segm = np.pad(segm, ((32,32),(32,32),(0,0)), constant_values=0)\n",
    "\n",
    "scan_patches = patchify(scan, PATCH_SIZE, step=PATCH_SIZE).reshape(-1,PATCH_SIZE[0],PATCH_SIZE[1],PATCH_SIZE[2])\n",
    "scan_patches = torch.tensor(scan_patches).float()\n",
    "scan_patches = torch.unsqueeze(scan_patches,1) # add channel dimension\n",
    "segm_patches = patchify(segm, PATCH_SIZE, step=PATCH_SIZE).reshape(-1,PATCH_SIZE[0],PATCH_SIZE[1],PATCH_SIZE[2]) \n",
    "segm_patches = one_hot(torch.tensor(segm_patches).to(torch.int64), num_classes=NUM_CLASSES).permute(0,4,1,2,3).float()\n",
    "\n",
    "\n",
    "print([scan_patches.shape, scan_patches.dtype])\n",
    "print([segm_patches.shape, segm_patches.dtype])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e52d820-1a53-4ed5-8833-53bc90067b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:14<00:00,  1.58s/it]\n"
     ]
    }
   ],
   "source": [
    "## Test ##\n",
    "pred_patches = np.zeros((scan_patches.shape[0], 5, PATCH_SIZE[0],PATCH_SIZE[1],PATCH_SIZE[2]))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(0,scan_patches.shape[0], TEST_BATCH_SIZE)):\n",
    "        batch = np.zeros((TEST_BATCH_SIZE, 1, PATCH_SIZE[0],PATCH_SIZE[1],PATCH_SIZE[2]))\n",
    "        \n",
    "        for j in range(0,TEST_BATCH_SIZE):\n",
    "            patch = {'name': 'patches', 'patch_scan': torch.Tensor(scan_patches[i+j])} \n",
    "            batch[j] = (val_transform(patch)['patch_scan'].float())\n",
    "            \n",
    "        pred = model(torch.Tensor(batch).cuda())\n",
    "        pred_patches[i:i+TEST_BATCH_SIZE] = pred.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4dd6e19-6698-4fe0-a0de-450e286af370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72, 96, 96, 96)\n",
      "(576, 576, 192)\n"
     ]
    }
   ],
   "source": [
    "# Unpatchify predictions\n",
    "pred_patches_reshape = np.array(pred_patches).reshape(scan_patches.shape[0],5,PATCH_SIZE[0],PATCH_SIZE[1],PATCH_SIZE[2])\n",
    "pred_patches_reshape = np.argmax(pred_patches_reshape, axis=1)\n",
    "print(pred_patches_reshape.shape)\n",
    "pred_patches_reshape = pred_patches_reshape.reshape(6,6,2,96,96,96)\n",
    "\n",
    "pred_unpatchified = unpatchify(pred_patches_reshape, segm.shape)\n",
    "print(pred_unpatchified.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c816a10-abf8-4ccb-be2d-561d5e962bdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87937167040c4f9b9840956c98cf1ef4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(RadioButtons(description='Slice plane selection:', options=('x-y', 'y-z', 'z-x'), style=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<utils.Visualization.ImageSliceViewer3D at 0x1465277e9670>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ImageSliceViewer3D(segm,pred_unpatchified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00bf9d9f-2a97-4bff-923b-6e539bce7306",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9708, 0.0099, 0.0897, 0.4562, 0.1189])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from unet3d.dice import *\n",
    "dice_coef_torch_multiclass(torch.Tensor(segm), torch.Tensor(pred_unpatchified), 5, one_hot_encoded=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38d319a-1eac-46ab-b7fa-696c334dd4e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
