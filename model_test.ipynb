{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import pkbar\n",
    "import sys\n",
    "from unet3d.config import *\n",
    "from tqdm import tqdm\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.nn.functional import one_hot\n",
    "from torch.optim import Adam\n",
    "from torchsummary import summary\n",
    "#from torch.utils.tensorboard import SummaryWriter\n",
    "from unet3d.unet3d_vgg16 import UNet3D_VGG16\n",
    "from utils.Visualization import ImageSliceViewer3D\n",
    "from patchify import patchify\n",
    "import nrrd\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 128/128 [00:01<00:00, 121.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.Size([128, 1, 96, 96, 96]), torch.float32]\n",
      "[torch.Size([128, 5, 96, 96, 96]), torch.float32]\n"
     ]
    }
   ],
   "source": [
    "# Load some data and uniformly sample from it\n",
    "scan, _ = nrrd.read(DATASET_PATH + '/SAIAD 1/scan.nrrd')\n",
    "segm, _ = nrrd.read(DATASET_PATH + '/SAIAD 1/segm.nrrd')\n",
    "\n",
    "#scan_patches = patchify(scan, PATCH_SIZE, step=PATCH_SIZE).reshape(-1,PATCH_SIZE[0],PATCH_SIZE[1], PATCH_SIZE[2])\n",
    "\n",
    "## Random Sampling: Uniform\n",
    "scan_patches = []\n",
    "segm_patches = []\n",
    "side_len = PATCH_SIZE[0]\n",
    "for i in tqdm(range(128)):\n",
    "    # Center coordinates\n",
    "    cx = torch.randint(0,scan.shape[0],(1,))[0]\n",
    "    cy = torch.randint(0,scan.shape[1],(1,))[0]\n",
    "    cz = torch.randint(0,scan.shape[2],(1,))[0]\n",
    "    \n",
    "    #print(f\"Center: {[cx,cy,cz]}\")\n",
    "    bbox_x = [max(cx - side_len//2, 0), min(scan.shape[0], cx+side_len//2)]\n",
    "    bbox_y = [max(cy - side_len//2, 0), min(scan.shape[1], cy+side_len//2)]\n",
    "    bbox_z = [max(cz - side_len//2, 0), min(scan.shape[2], cz+side_len//2)]\n",
    "\n",
    "    # Random patch\n",
    "    pad_x = (-min(cx - side_len//2,0), max(side_len//2 + cx - scan.shape[0], 0))\n",
    "    pad_y = (-min(cy - side_len//2,0), max(side_len//2 + cy - scan.shape[1], 0))\n",
    "    pad_z = (-min(cz - side_len//2,0), max(side_len//2 + cz - scan.shape[2], 0))\n",
    "    \n",
    "    #print([pad_x, pad_y, pad_z])\n",
    "\n",
    "    segm_patch_prepad = segm[bbox_x[0]:bbox_x[1], bbox_y[0]:bbox_y[1], bbox_z[0]:bbox_z[1]]\n",
    "    scan_patch_prepad = scan[bbox_x[0]:bbox_x[1], bbox_y[0]:bbox_y[1], bbox_z[0]:bbox_z[1]]\n",
    "    scan_patch = np.pad(scan_patch_prepad,(pad_x, pad_y, pad_z), 'constant', constant_values=0)\n",
    "    segm_patch = np.pad(segm_patch_prepad,(pad_x, pad_y, pad_z), 'constant', constant_values=0)\n",
    "    \n",
    "    scan_patches.append(scan_patch)\n",
    "    segm_patches.append(segm_patch)\n",
    "    \n",
    "scan_patches = torch.tensor(np.array(scan_patches)).float()\n",
    "scan_patches = torch.unsqueeze(scan_patches,1) # add channel dimension, send to gpu\n",
    "segm_patches = np.array(segm_patches).reshape(-1,PATCH_SIZE[0],PATCH_SIZE[1], PATCH_SIZE[2])\n",
    "segm_patches = one_hot(torch.tensor(segm_patches).to(torch.int64), num_classes=NUM_CLASSES).permute(0,4,1,2,3).float()# put channels first, send to gpu\n",
    "\n",
    "print([scan_patches.shape, scan_patches.dtype])\n",
    "print([segm_patches.shape, segm_patches.dtype])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100\n",
      "32/32 [========] - 35s 1s/step - loss: 32.8316 - Validation loss: 10.6068\n",
      "Epoch: 2/100\n",
      "32/32 [========] - 27s 840ms/step - loss: 19.2562 - Validation loss: 6.2339\n",
      "Epoch: 3/100\n",
      "32/32 [========] - 27s 838ms/step - loss: 11.2036 - Validation loss: 3.8491\n",
      "Epoch: 4/100\n",
      "32/32 [========] - 26s 816ms/step - loss: 7.3448 - Validation loss: 3.1102\n",
      "Epoch: 5/100\n",
      "32/32 [========] - 27s 842ms/step - loss: 5.5490 - Validation loss: 2.6537\n",
      "Epoch: 6/100\n",
      "32/32 [========] - 26s 815ms/step - loss: 4.6612 - Validation loss: 2.1078\n",
      "Epoch: 7/100\n",
      "32/32 [========] - 27s 840ms/step - loss: 4.0203 - Validation loss: 2.0358\n",
      "Epoch: 8/100\n",
      "32/32 [========] - 26s 815ms/step - loss: 3.6960 - Validation loss: 2.0935\n",
      "Epoch: 9/100\n",
      "32/32 [========] - 27s 840ms/step - loss: 3.5013 - Validation loss: 1.7976\n",
      "Epoch: 10/100\n",
      "32/32 [========] - 26s 815ms/step - loss: 3.1605 - Validation loss: 2.0564\n",
      "Epoch: 11/100\n",
      "32/32 [========] - 27s 839ms/step - loss: 2.9271 - Validation loss: 1.7098\n",
      "Epoch: 12/100\n",
      "32/32 [========] - 26s 816ms/step - loss: 2.9463 - Validation loss: 1.4488\n",
      "Epoch: 13/100\n",
      "32/32 [========] - 27s 838ms/step - loss: 2.7398 - Validation loss: 1.4917\n",
      "Epoch: 14/100\n",
      "32/32 [========] - 26s 817ms/step - loss: 2.8768 - Validation loss: 1.6626\n",
      "Epoch: 15/100\n",
      "32/32 [========] - 27s 840ms/step - loss: 2.7273 - Validation loss: 1.5353\n",
      "Epoch: 16/100\n",
      "32/32 [========] - 26s 817ms/step - loss: 2.6765 - Validation loss: 1.1836\n",
      "Epoch: 17/100\n",
      "32/32 [========] - 27s 838ms/step - loss: 2.6281 - Validation loss: 1.3383\n",
      "Epoch: 18/100\n",
      "32/32 [========] - 26s 818ms/step - loss: 2.4904 - Validation loss: 1.2001\n",
      "Epoch: 19/100\n",
      "32/32 [========] - 27s 837ms/step - loss: 2.3746 - Validation loss: 1.2331\n",
      "Epoch: 20/100\n",
      "32/32 [========] - 26s 818ms/step - loss: 2.3404 - Validation loss: 1.1704\n",
      "Epoch: 21/100\n",
      "32/32 [========] - 27s 837ms/step - loss: 2.2311 - Validation loss: 1.2228\n",
      "Epoch: 22/100\n",
      "32/32 [========] - 26s 819ms/step - loss: 2.2080 - Validation loss: 1.1672\n",
      "Epoch: 23/100\n",
      "32/32 [========] - 27s 836ms/step - loss: 2.1596 - Validation loss: 1.1598\n",
      "Epoch: 24/100\n",
      "32/32 [========] - 26s 819ms/step - loss: 2.3521 - Validation loss: 1.1404\n",
      "Epoch: 25/100\n",
      "32/32 [========] - 27s 832ms/step - loss: 2.2037 - Validation loss: 1.0112\n",
      "Epoch: 26/100\n",
      "32/32 [========] - 26s 825ms/step - loss: 2.2361 - Validation loss: 1.0564\n",
      "Epoch: 27/100\n",
      "21/32 [====>...] - ETA: 10s - loss: 1.8420"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     30\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 31\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m kbar\u001b[38;5;241m.\u001b[39mupdate(j, values\u001b[38;5;241m=\u001b[39m[(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m, train_loss)])\n\u001b[1;32m     33\u001b[0m j\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training\n",
    "torch.backends.cudnn.benchmark = True # Speeds up stuff\n",
    "torch.backends.cudnn.enabled = True\n",
    "\n",
    "TRAIN_BATCH_SIZE = 4\n",
    "VAL_BATCH_SIZE = 4\n",
    "\n",
    "device = torch.device('cuda')\n",
    "model = UNet3D_VGG16(in_channels=IN_CHANNELS , num_classes=NUM_CLASSES).cuda()\n",
    "loss_fn = CrossEntropyLoss().cuda()#weight=torch.Tensor(np.array(CE_WEIGHTS)/np.array(CE_WEIGHTS).sum())).cuda()\n",
    "optimizer = Adam(params=model.parameters(), lr=LR)\n",
    "\n",
    "min_valid_loss = math.inf\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # progress bar\n",
    "    kbar = pkbar.Kbar(target=128/TRAIN_BATCH_SIZE, epoch=epoch, num_epochs=EPOCHS, width=8, always_stateful=True)\n",
    "\n",
    "    train_loss = 0.0\n",
    "    model.train()\n",
    "    j=1\n",
    "    # Autocasting for mixed precision\n",
    "    #with torch.cuda.amp.autocast():\n",
    "    for i in range(0,96, TRAIN_BATCH_SIZE):\n",
    "        X_batch, y_batch = scan_patches[i:i+TRAIN_BATCH_SIZE].cuda(), segm_patches[i:i+TRAIN_BATCH_SIZE].cuda()\n",
    "        target = model(X_batch)\n",
    "        loss = loss_fn(target, y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        kbar.update(j, values=[(\"loss\", train_loss)])\n",
    "        j+=1\n",
    "    \n",
    "    valid_loss = 0.0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i in range(96,128, VAL_BATCH_SIZE):\n",
    "            X_batch, y_batch = scan_patches[i:i+VAL_BATCH_SIZE].cuda(), segm_patches[i:i+VAL_BATCH_SIZE].cuda()\n",
    "            target = model(X_batch)\n",
    "            loss = loss_fn(target,y_batch)\n",
    "            valid_loss += loss.item()\n",
    "            kbar.update(j, values=[(\"Validation loss\", valid_loss)])\n",
    "            j+=1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbdb05a012d341849458033d0683131f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(RadioButtons(description='Slice plane selection:', options=('x-y', 'y-z', 'z-x'), style=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<utils.Visualization.ImageSliceViewer3D at 0x151724f16a90>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.Visualization import ImageSliceViewer3D\n",
    "n=70\n",
    "pred = model(scan_patches[n:n+1].cuda())\n",
    "pred.size()\n",
    "pred_index = np.array(torch.argmax(pred[0].cpu(), dim=0))\n",
    "ImageSliceViewer3D(pred_index, np.array(scan_patches[n:n+1][0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4688, device='cuda:0', grad_fn=<DivBackward1>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(pred, segm_patches[n:n+1].cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([nan, nan, nan,  ..., nan, nan, nan], device='cuda:0',\n",
       "       grad_fn=<Unique2Backward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unique(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 36 125  77  99  75  91  95 110  57 102  11 111  80  97  40  17 126  53\n",
      "   2  54  30 123 116  28  23  93  81  88  49  46  96  62  90 124  61   3\n",
      "   7  86  34   6  55  84 109   9  20   5  78  67 112  64  25  44  10  92\n",
      "  66  98 108  59  41  50  24  63 117  76 104 120  56   8  26  43  33  37\n",
      "  89   4 106  14   1  35 107 114   0  45  94  69 100  83  18  60  12 119\n",
      "  70  51  31  87  16  22 115  13  38 127  42  68  74 118 103 121 101 122\n",
      "  15  19  85  73  58  29  21  52 105  39  82  79  47  71 113  72  48  65\n",
      "  27  32]\n"
     ]
    }
   ],
   "source": [
    "idx = np.arange(128)\n",
    "np.random.shuffle(idx)\n",
    "print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv3d-1       [-1, 32, 96, 96, 96]             896\n",
      "       BatchNorm3d-2       [-1, 32, 96, 96, 96]              64\n",
      "              ReLU-3       [-1, 32, 96, 96, 96]               0\n",
      "            Conv3d-4       [-1, 64, 96, 96, 96]          55,360\n",
      "       BatchNorm3d-5       [-1, 64, 96, 96, 96]             128\n",
      "              ReLU-6       [-1, 64, 96, 96, 96]               0\n",
      "         MaxPool3d-7       [-1, 64, 48, 48, 48]               0\n",
      "       Conv3DBlock-8  [[-1, 64, 48, 48, 48], [-1, 64, 96, 96, 96]]               0\n",
      "            Conv3d-9       [-1, 64, 48, 48, 48]         110,656\n",
      "      BatchNorm3d-10       [-1, 64, 48, 48, 48]             128\n",
      "             ReLU-11       [-1, 64, 48, 48, 48]               0\n",
      "           Conv3d-12      [-1, 128, 48, 48, 48]         221,312\n",
      "      BatchNorm3d-13      [-1, 128, 48, 48, 48]             256\n",
      "             ReLU-14      [-1, 128, 48, 48, 48]               0\n",
      "        MaxPool3d-15      [-1, 128, 24, 24, 24]               0\n",
      "      Conv3DBlock-16  [[-1, 128, 24, 24, 24], [-1, 128, 48, 48, 48]]               0\n",
      "           Conv3d-17      [-1, 128, 24, 24, 24]         442,496\n",
      "      BatchNorm3d-18      [-1, 128, 24, 24, 24]             256\n",
      "             ReLU-19      [-1, 128, 24, 24, 24]               0\n",
      "           Conv3d-20      [-1, 256, 24, 24, 24]         884,992\n",
      "      BatchNorm3d-21      [-1, 256, 24, 24, 24]             512\n",
      "             ReLU-22      [-1, 256, 24, 24, 24]               0\n",
      "        MaxPool3d-23      [-1, 256, 12, 12, 12]               0\n",
      "      Conv3DBlock-24  [[-1, 256, 12, 12, 12], [-1, 256, 24, 24, 24]]               0\n",
      "           Conv3d-25      [-1, 256, 12, 12, 12]       1,769,728\n",
      "      BatchNorm3d-26      [-1, 256, 12, 12, 12]             512\n",
      "             ReLU-27      [-1, 256, 12, 12, 12]               0\n",
      "           Conv3d-28      [-1, 512, 12, 12, 12]       3,539,456\n",
      "      BatchNorm3d-29      [-1, 512, 12, 12, 12]           1,024\n",
      "             ReLU-30      [-1, 512, 12, 12, 12]               0\n",
      "      Conv3DBlock-31  [[-1, 512, 12, 12, 12], [-1, 512, 12, 12, 12]]               0\n",
      "  ConvTranspose3d-32      [-1, 512, 24, 24, 24]       2,097,664\n",
      "           Conv3d-33      [-1, 256, 24, 24, 24]       5,308,672\n",
      "      BatchNorm3d-34      [-1, 256, 24, 24, 24]             512\n",
      "             ReLU-35      [-1, 256, 24, 24, 24]               0\n",
      "           Conv3d-36      [-1, 256, 24, 24, 24]       1,769,728\n",
      "      BatchNorm3d-37      [-1, 256, 24, 24, 24]             512\n",
      "             ReLU-38      [-1, 256, 24, 24, 24]               0\n",
      "    UpConv3DBlock-39      [-1, 256, 24, 24, 24]               0\n",
      "  ConvTranspose3d-40      [-1, 256, 48, 48, 48]         524,544\n",
      "           Conv3d-41      [-1, 128, 48, 48, 48]       1,327,232\n",
      "      BatchNorm3d-42      [-1, 128, 48, 48, 48]             256\n",
      "             ReLU-43      [-1, 128, 48, 48, 48]               0\n",
      "           Conv3d-44      [-1, 128, 48, 48, 48]         442,496\n",
      "      BatchNorm3d-45      [-1, 128, 48, 48, 48]             256\n",
      "             ReLU-46      [-1, 128, 48, 48, 48]               0\n",
      "    UpConv3DBlock-47      [-1, 128, 48, 48, 48]               0\n",
      "  ConvTranspose3d-48      [-1, 128, 96, 96, 96]         131,200\n",
      "           Conv3d-49       [-1, 64, 96, 96, 96]         331,840\n",
      "      BatchNorm3d-50       [-1, 64, 96, 96, 96]             128\n",
      "             ReLU-51       [-1, 64, 96, 96, 96]               0\n",
      "           Conv3d-52       [-1, 64, 96, 96, 96]         110,656\n",
      "      BatchNorm3d-53       [-1, 64, 96, 96, 96]             128\n",
      "             ReLU-54       [-1, 64, 96, 96, 96]               0\n",
      "           Conv3d-55        [-1, 5, 96, 96, 96]             325\n",
      "    UpConv3DBlock-56        [-1, 5, 96, 96, 96]               0\n",
      "================================================================\n",
      "Total params: 19,073,925\n",
      "Trainable params: 19,073,925\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 3.38\n",
      "Forward/backward pass size (MB): 3266659104.75\n",
      "Params size (MB): 72.76\n",
      "Estimated Total Size (MB): 3266659180.89\n",
      "----------------------------------------------------------------\n",
      "--- 0.05122971534729004 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "torch.cuda.empty_cache()\n",
    "start_time = time.time()\n",
    "summary(model=model, input_size=(1, 96,96,96), batch_size=-1, device=\"cuda\")\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "32aad0a8508bff835c20a8d47234734688fb62c0cbdf7488c1eae1822cd413fe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
