{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import pkbar\n",
    "import sys\n",
    "from unet3d.config import *\n",
    "from tqdm import tqdm\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.nn.functional import one_hot\n",
    "from torch.optim import Adam\n",
    "from torchsummary import summary\n",
    "#from torch.utils.tensorboard import SummaryWriter\n",
    "from unet3d.unet3d import UNet3D\n",
    "from utils.Visualization import ImageSliceViewer3D\n",
    "from patchify import patchify\n",
    "import nrrd\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 128/128 [00:01<00:00, 125.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.Size([128, 1, 96, 96, 96]), torch.float32]\n",
      "[torch.Size([128, 5, 96, 96, 96]), torch.float32]\n"
     ]
    }
   ],
   "source": [
    "# Load some data and uniformly sample from it\n",
    "scan, _ = nrrd.read(DATASET_PATH + '/SAIAD 1/scan.nrrd')\n",
    "segm, _ = nrrd.read(DATASET_PATH + '/SAIAD 1/segm.nrrd')\n",
    "\n",
    "#scan_patches = patchify(scan, PATCH_SIZE, step=PATCH_SIZE).reshape(-1,PATCH_SIZE[0],PATCH_SIZE[1], PATCH_SIZE[2])\n",
    "\n",
    "\n",
    "## Random Sampling: Uniform\n",
    "scan_patches = []\n",
    "segm_patches = []\n",
    "side_len = PATCH_SIZE[0]\n",
    "for i in tqdm(range(128)):\n",
    "    # Center coordinates\n",
    "    cx = torch.randint(0,scan.shape[0],(1,))[0]\n",
    "    cy = torch.randint(0,scan.shape[1],(1,))[0]\n",
    "    cz = torch.randint(0,scan.shape[2],(1,))[0]\n",
    "    \n",
    "    #print(f\"Center: {[cx,cy,cz]}\")\n",
    "    bbox_x = [max(cx - side_len//2, 0), min(scan.shape[0], cx+side_len//2)]\n",
    "    bbox_y = [max(cy - side_len//2, 0), min(scan.shape[1], cy+side_len//2)]\n",
    "    bbox_z = [max(cz - side_len//2, 0), min(scan.shape[2], cz+side_len//2)]\n",
    "\n",
    "    # Random patch\n",
    "    pad_x = (-min(cx - side_len//2,0), max(side_len//2 + cx - scan.shape[0], 0))\n",
    "    pad_y = (-min(cy - side_len//2,0), max(side_len//2 + cy - scan.shape[1], 0))\n",
    "    pad_z = (-min(cz - side_len//2,0), max(side_len//2 + cz - scan.shape[2], 0))\n",
    "    \n",
    "    #print([pad_x, pad_y, pad_z])\n",
    "\n",
    "    segm_patch_prepad = segm[bbox_x[0]:bbox_x[1], bbox_y[0]:bbox_y[1], bbox_z[0]:bbox_z[1]]\n",
    "    scan_patch_prepad = scan[bbox_x[0]:bbox_x[1], bbox_y[0]:bbox_y[1], bbox_z[0]:bbox_z[1]]\n",
    "    scan_patch = np.pad(scan_patch_prepad,(pad_x, pad_y, pad_z), 'constant', constant_values=0)\n",
    "    segm_patch = np.pad(segm_patch_prepad,(pad_x, pad_y, pad_z), 'constant', constant_values=0)\n",
    "    \n",
    "    scan_patches.append(scan_patch)\n",
    "    segm_patches.append(segm_patch)\n",
    "    \n",
    "scan_patches = torch.tensor(np.array(scan_patches)).float()\n",
    "scan_patches = torch.unsqueeze(scan_patches,1) # add channel dimension, send to gpu\n",
    "segm_patches = np.array(segm_patches).reshape(-1,PATCH_SIZE[0],PATCH_SIZE[1], PATCH_SIZE[2])\n",
    "segm_patches = one_hot(torch.tensor(segm_patches).to(torch.int64), num_classes=NUM_CLASSES).permute(0,4,1,2,3).float()# put channels first, send to gpu\n",
    "\n",
    "print([scan_patches.shape, scan_patches.dtype])\n",
    "print([segm_patches.shape, segm_patches.dtype])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100\n",
      "126/120 [========] - 91s 721ms/step - loss: 0.4291 - Validation loss: 0.0508\n",
      "Validation Loss Decreased(inf--->0.050767) \t Saving The Model\n",
      "Epoch: 2/100\n",
      "126/120 [========] - 91s 724ms/step - loss: 0.2082 - Validation loss: 0.0401\n",
      "Validation Loss Decreased(0.050767--->0.040131) \t Saving The Model\n",
      "Epoch: 3/100\n",
      "126/120 [========] - 92s 727ms/step - loss: 0.1677 - Validation loss: 0.0439\n",
      "Epoch: 4/100\n",
      "126/120 [========] - 92s 728ms/step - loss: 0.1727 - Validation loss: 0.0453\n",
      "Epoch: 5/100\n",
      "126/120 [========] - 92s 729ms/step - loss: 0.1648 - Validation loss: 0.0488\n",
      "Epoch: 6/100\n",
      "126/120 [========] - 92s 728ms/step - loss: 0.1544 - Validation loss: 0.0418\n",
      "Epoch: 7/100\n",
      "126/120 [========] - 91s 726ms/step - loss: 0.1435 - Validation loss: 0.0505\n",
      "Epoch: 8/100\n",
      "126/120 [========] - 92s 726ms/step - loss: 0.1416 - Validation loss: 0.0548\n",
      "Epoch: 9/100\n",
      "126/120 [========] - 92s 726ms/step - loss: 0.1435 - Validation loss: 0.0460\n",
      "Epoch: 10/100\n",
      "126/120 [========] - 92s 727ms/step - loss: 0.1313 - Validation loss: 0.0539\n",
      "Epoch: 11/100\n",
      "126/120 [========] - 92s 726ms/step - loss: 0.1303 - Validation loss: 0.0553\n",
      "Epoch: 12/100\n",
      "126/120 [========] - 92s 727ms/step - loss: 0.1233 - Validation loss: 0.0549\n",
      "Epoch: 13/100\n",
      "126/120 [========] - 92s 727ms/step - loss: 0.1212 - Validation loss: 0.0561\n",
      "Epoch: 14/100\n",
      "126/120 [========] - 92s 728ms/step - loss: 0.1178 - Validation loss: 0.0564\n",
      "Epoch: 15/100\n",
      "126/120 [========] - 92s 727ms/step - loss: 0.1239 - Validation loss: 0.0639\n",
      "Epoch: 16/100\n",
      "126/120 [========] - 92s 727ms/step - loss: 0.1119 - Validation loss: 0.0552\n",
      "Epoch: 17/100\n",
      "126/120 [========] - 92s 726ms/step - loss: 0.1087 - Validation loss: 0.0519\n",
      "Epoch: 18/100\n",
      "126/120 [========] - 92s 726ms/step - loss: 0.1021 - Validation loss: 0.0652\n",
      "Epoch: 19/100\n",
      "126/120 [========] - 92s 727ms/step - loss: 0.1281 - Validation loss: 0.0496\n",
      "Epoch: 20/100\n",
      "126/120 [========] - 92s 726ms/step - loss: 0.1333 - Validation loss: 0.0429\n",
      "Epoch: 21/100\n",
      "126/120 [========] - 92s 726ms/step - loss: 0.1334 - Validation loss: 0.0591\n",
      "Epoch: 22/100\n",
      "126/120 [========] - 92s 726ms/step - loss: 0.1231 - Validation loss: 0.0510\n",
      "Epoch: 23/100\n",
      "126/120 [========] - 92s 726ms/step - loss: 0.1133 - Validation loss: 0.0646\n",
      "Epoch: 24/100\n",
      "126/120 [========] - 91s 726ms/step - loss: 0.1066 - Validation loss: 0.0521\n",
      "Epoch: 25/100\n",
      "126/120 [========] - 92s 727ms/step - loss: 0.0979 - Validation loss: 0.0558\n",
      "Epoch: 26/100\n",
      "126/120 [========] - 92s 727ms/step - loss: 0.0904 - Validation loss: 0.1097\n",
      "Epoch: 27/100\n",
      "126/120 [========] - 92s 727ms/step - loss: 0.1068 - Validation loss: 0.0524\n",
      "Epoch: 28/100\n",
      "126/120 [========] - 92s 727ms/step - loss: 0.0849 - Validation loss: 0.0628\n",
      "Epoch: 29/100\n",
      "126/120 [========] - 92s 727ms/step - loss: 0.1102 - Validation loss: 0.0780\n",
      "Epoch: 30/100\n",
      "126/120 [========] - 92s 727ms/step - loss: 0.0916 - Validation loss: 0.0743\n",
      "Epoch: 31/100\n",
      "126/120 [========] - 92s 726ms/step - loss: 0.0779 - Validation loss: 0.0893\n",
      "Epoch: 32/100\n",
      "126/120 [========] - 92s 727ms/step - loss: 0.0898 - Validation loss: 0.0781\n",
      "Epoch: 33/100\n",
      "126/120 [========] - 92s 727ms/step - loss: 0.0810 - Validation loss: 0.0768\n",
      "Epoch: 34/100\n",
      "126/120 [========] - 92s 728ms/step - loss: 0.0709 - Validation loss: 0.0812\n",
      "Epoch: 35/100\n",
      "126/120 [========] - 92s 728ms/step - loss: 0.0876 - Validation loss: 0.0779\n",
      "Epoch: 36/100\n",
      "126/120 [========] - 92s 727ms/step - loss: 0.1008 - Validation loss: 0.0676\n",
      "Epoch: 37/100\n",
      "126/120 [========] - 92s 727ms/step - loss: 0.0844 - Validation loss: 0.0557\n",
      "Epoch: 38/100\n",
      "126/120 [========] - 92s 727ms/step - loss: 0.0671 - Validation loss: 0.0724\n",
      "Epoch: 39/100\n",
      "126/120 [========] - 92s 728ms/step - loss: 0.0585 - Validation loss: 0.0709\n",
      "Epoch: 40/100\n",
      "126/120 [========] - 92s 727ms/step - loss: 0.0562 - Validation loss: 0.0679\n",
      "Epoch: 41/100\n",
      "126/120 [========] - 92s 727ms/step - loss: 0.0590 - Validation loss: 0.0706\n",
      "Epoch: 42/100\n",
      "126/120 [========] - 92s 727ms/step - loss: 0.0527 - Validation loss: 0.0742\n",
      "Epoch: 43/100\n",
      "126/120 [========] - 92s 728ms/step - loss: 0.0558 - Validation loss: 0.0691\n",
      "Epoch: 44/100\n",
      "126/120 [========] - 92s 728ms/step - loss: 0.0981 - Validation loss: 0.0506\n",
      "Epoch: 45/100\n",
      "126/120 [========] - 92s 728ms/step - loss: 0.0665 - Validation loss: 0.0776\n",
      "Epoch: 46/100\n",
      "126/120 [========] - 92s 727ms/step - loss: 0.0622 - Validation loss: 0.0672\n",
      "Epoch: 47/100\n",
      "126/120 [========] - 92s 727ms/step - loss: 0.0495 - Validation loss: 0.0720\n",
      "Epoch: 48/100\n",
      "126/120 [========] - 92s 727ms/step - loss: 0.0493 - Validation loss: 0.0719\n",
      "Epoch: 49/100\n",
      "126/120 [========] - 92s 727ms/step - loss: 0.0470 - Validation loss: 0.0714\n",
      "Epoch: 50/100\n",
      "126/120 [========] - 92s 727ms/step - loss: 0.0384 - Validation loss: 0.0690\n",
      "Epoch: 51/100\n",
      "126/120 [========] - 92s 727ms/step - loss: 0.0380 - Validation loss: 0.0777\n",
      "Epoch: 52/100\n",
      "126/120 [========] - 92s 727ms/step - loss: 0.0397 - Validation loss: 0.0614\n",
      "Epoch: 53/100\n",
      "126/120 [========] - 92s 727ms/step - loss: 0.0780 - Validation loss: 0.0748\n",
      "Epoch: 54/100\n",
      "126/120 [========] - 92s 727ms/step - loss: 0.0875 - Validation loss: 0.0696\n",
      "Epoch: 55/100\n",
      "126/120 [========] - 92s 728ms/step - loss: 0.0958 - Validation loss: 0.0923\n",
      "Epoch: 56/100\n",
      "126/120 [========] - 92s 726ms/step - loss: 0.0777 - Validation loss: 0.0511\n",
      "Epoch: 57/100\n",
      "126/120 [========] - 91s 726ms/step - loss: 0.0542 - Validation loss: 0.0608\n",
      "Epoch: 58/100\n",
      "126/120 [========] - 92s 727ms/step - loss: 0.0465 - Validation loss: 0.0628\n",
      "Epoch: 59/100\n",
      "126/120 [========] - 92s 727ms/step - loss: 0.0355 - Validation loss: 0.0729\n",
      "Epoch: 60/100\n",
      "126/120 [========] - 92s 727ms/step - loss: 0.0303 - Validation loss: 0.0738\n",
      "Epoch: 61/100\n",
      "126/120 [========] - 92s 727ms/step - loss: 0.0291 - Validation loss: 0.0808\n",
      "Epoch: 62/100\n",
      "126/120 [========] - 92s 726ms/step - loss: 0.0252 - Validation loss: 0.0765\n",
      "Epoch: 63/100\n",
      "126/120 [========] - 92s 726ms/step - loss: 0.0355 - Validation loss: 0.0767\n",
      "Epoch: 64/100\n",
      "126/120 [========] - 92s 727ms/step - loss: 0.0481 - Validation loss: 0.1239\n",
      "Epoch: 65/100\n",
      "126/120 [========] - 92s 727ms/step - loss: 0.1025 - Validation loss: 0.0721\n",
      "Epoch: 66/100\n",
      "126/120 [========] - 91s 726ms/step - loss: 0.0633 - Validation loss: 0.0527\n",
      "Epoch: 67/100\n",
      "126/120 [========] - 92s 727ms/step - loss: 0.0407 - Validation loss: 0.0646\n",
      "Epoch: 68/100\n",
      "126/120 [========] - 92s 726ms/step - loss: 0.0336 - Validation loss: 0.0631\n",
      "Epoch: 69/100\n",
      "126/120 [========] - 92s 726ms/step - loss: 0.0256 - Validation loss: 0.0653\n",
      "Epoch: 70/100\n",
      "126/120 [========] - 91s 726ms/step - loss: 0.0230 - Validation loss: 0.0698\n",
      "Epoch: 71/100\n",
      "126/120 [========] - 92s 726ms/step - loss: 0.0214 - Validation loss: 0.0691\n",
      "Epoch: 72/100\n",
      "126/120 [========] - 92s 726ms/step - loss: 0.0198 - Validation loss: 0.0725\n",
      "Epoch: 73/100\n",
      "126/120 [========] - 91s 726ms/step - loss: 0.0268 - Validation loss: 0.0756\n",
      "Epoch: 74/100\n",
      "126/120 [========] - 92s 726ms/step - loss: 0.0252 - Validation loss: 0.0676\n",
      "Epoch: 75/100\n",
      "126/120 [========] - 92s 727ms/step - loss: 0.0199 - Validation loss: 0.0842\n",
      "Epoch: 76/100\n",
      "126/120 [========] - 92s 727ms/step - loss: 0.0185 - Validation loss: 0.0780\n",
      "Epoch: 77/100\n",
      "126/120 [========] - 92s 727ms/step - loss: 0.0158 - Validation loss: 0.0831\n",
      "Epoch: 78/100\n",
      "126/120 [========] - 92s 727ms/step - loss: 0.0205 - Validation loss: 0.0756\n",
      "Epoch: 79/100\n",
      "126/120 [========] - 92s 726ms/step - loss: 0.0175 - Validation loss: 0.0864\n",
      "Epoch: 80/100\n",
      "126/120 [========] - 92s 727ms/step - loss: 0.0168 - Validation loss: 0.0839\n",
      "Epoch: 81/100\n",
      "126/120 [========] - 92s 727ms/step - loss: 0.0173 - Validation loss: 0.0786\n",
      "Epoch: 82/100\n",
      "126/120 [========] - 92s 727ms/step - loss: 0.0212 - Validation loss: 0.0896\n",
      "Epoch: 83/100\n",
      "126/120 [========] - 92s 727ms/step - loss: 0.0164 - Validation loss: 0.0900\n",
      "Epoch: 84/100\n",
      "126/120 [========] - 92s 727ms/step - loss: 0.0150 - Validation loss: 0.0814\n",
      "Epoch: 85/100\n",
      "126/120 [========] - 92s 727ms/step - loss: 0.0145 - Validation loss: 0.0848\n",
      "Epoch: 86/100\n",
      "126/120 [========] - 92s 727ms/step - loss: 0.0138 - Validation loss: 0.0828\n",
      "Epoch: 87/100\n",
      "126/120 [========] - 92s 727ms/step - loss: 0.0140 - Validation loss: 0.0864\n",
      "Epoch: 88/100\n",
      "126/120 [========] - 92s 727ms/step - loss: 0.0152 - Validation loss: 0.0763\n",
      "Epoch: 89/100\n",
      "126/120 [========] - 92s 727ms/step - loss: 0.0196 - Validation loss: 0.0935\n",
      "Epoch: 90/100\n",
      "126/120 [========] - 92s 727ms/step - loss: 0.0201 - Validation loss: 0.0715\n",
      "Epoch: 91/100\n",
      "126/120 [========] - 92s 727ms/step - loss: 0.0183 - Validation loss: 0.0696\n",
      "Epoch: 92/100\n",
      "108/120 [======>.] - ETA: 9s - loss: 0.0138 "
     ]
    }
   ],
   "source": [
    "# Training\n",
    "#writer = SummaryWriter(\"runs\")\n",
    "device = torch.device('cuda')\n",
    "model = UNet3D(in_channels=IN_CHANNELS , num_classes= NUM_CLASSES).cuda()\n",
    "criterion = CrossEntropyLoss(weight=torch.Tensor(np.array(CE_WEIGHTS)/np.array(CE_WEIGHTS).sum())).cuda()\n",
    "optimizer = Adam(params=model.parameters())\n",
    "\n",
    "min_valid_loss = math.inf\n",
    "\n",
    "for epoch in range(TRAINING_EPOCH):\n",
    "    # progress bar\n",
    "    kbar = pkbar.Kbar(target=120, epoch=epoch, num_epochs=TRAINING_EPOCH, width=8, always_stateful=False)\n",
    "\n",
    "    train_loss = 0.0\n",
    "    model.train()\n",
    "    for i in range(0,120,TRAIN_BATCH_SIZE):\n",
    "        image, ground_truth = scan_patches[i:i+TRAIN_BATCH_SIZE], segm_patches[i:i+TRAIN_BATCH_SIZE]\n",
    "    \n",
    "        # send to gpu\n",
    "        image, ground_truth = image.cuda(), ground_truth.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        target = model(image).cuda()\n",
    "        loss = criterion(target, ground_truth)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        kbar.update(i, values=[(\"loss\", train_loss)])\n",
    "    \n",
    "    valid_loss = 0.0\n",
    "    model.eval()\n",
    "    for i in range(120,128,TRAIN_BATCH_SIZE):\n",
    "        image, ground_truth = scan_patches[i:i+TRAIN_BATCH_SIZE], segm_patches[i:i+TRAIN_BATCH_SIZE]\n",
    "        image, ground_truth = image.cuda(), ground_truth.cuda()\n",
    "        target = model(image).cuda()\n",
    "        loss = criterion(target,ground_truth)\n",
    "        valid_loss += loss.item()\n",
    "    kbar.update(i, values=[(\"Validation loss\", valid_loss)])\n",
    "\n",
    "        \n",
    "    #writer.add_scalar(\"Loss/Train\", train_loss / 120, epoch)\n",
    "    #writer.add_scalar(\"Loss/Validation\", valid_loss / 8, epoch)\n",
    "    \n",
    "    #print(f'Epoch {epoch+1} \\t\\t Training Loss: {train_loss / 8} \\t\\t Validation Loss: {valid_loss / 8}')\n",
    "    \n",
    "    if min_valid_loss > valid_loss:\n",
    "        print(f'Validation Loss Decreased({min_valid_loss:.6f}--->{valid_loss:.6f}) \\t Saving The Model')\n",
    "        min_valid_loss = valid_loss\n",
    "        # Saving State Dict\n",
    "        torch.save(model.state_dict(), f'checkpoints/test_epoch{epoch}_valLoss{min_valid_loss}.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 64, 64, 64])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n=58\n",
    "pred = model(scan_patches[n:n+1].cuda())\n",
    "pred.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "516f242ed03c43669207b926af5f050a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(RadioButtons(description='Slice plane selection:', options=('x-y', 'y-z', 'z-x'), style=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<utils.Visualization.ImageSliceViewer3D at 0x154ffd1cc4c0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.Visualization import ImageSliceViewer3D\n",
    "pred_index = np.array(torch.argmax(pred[0].cpu(), dim=0))\n",
    "ImageSliceViewer3D(pred_index, np.array(scan_patches[n:n+1][0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee60d275367b442588bb17c7fbe91ad1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(RadioButtons(description='Slice plane selection:', options=('x-y', 'y-z', 'z-x'), style=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<utils.Visualization.ImageSliceViewer3D at 0x1550a2496970>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ImageSliceViewer3D(np.array(scan_patches[n:n+1][0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(scan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 36 125  77  99  75  91  95 110  57 102  11 111  80  97  40  17 126  53\n",
      "   2  54  30 123 116  28  23  93  81  88  49  46  96  62  90 124  61   3\n",
      "   7  86  34   6  55  84 109   9  20   5  78  67 112  64  25  44  10  92\n",
      "  66  98 108  59  41  50  24  63 117  76 104 120  56   8  26  43  33  37\n",
      "  89   4 106  14   1  35 107 114   0  45  94  69 100  83  18  60  12 119\n",
      "  70  51  31  87  16  22 115  13  38 127  42  68  74 118 103 121 101 122\n",
      "  15  19  85  73  58  29  21  52 105  39  82  79  47  71 113  72  48  65\n",
      "  27  32]\n"
     ]
    }
   ],
   "source": [
    "idx = np.arange(128)\n",
    "np.random.shuffle(idx)\n",
    "print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "torch.cuda.empty_cache()\n",
    "start_time = time.time()\n",
    "summary(model=model, input_size=(1, 96,96,96), batch_size=-1, device=\"cuda\")\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "32aad0a8508bff835c20a8d47234734688fb62c0cbdf7488c1eae1822cd413fe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
