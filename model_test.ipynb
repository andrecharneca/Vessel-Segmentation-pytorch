{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import pkbar\n",
    "import sys\n",
    "from unet3d.config import *\n",
    "from tqdm import tqdm\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.nn.functional import one_hot\n",
    "from torch.optim import Adam\n",
    "from torchsummary import summary\n",
    "#from torch.utils.tensorboard import SummaryWriter\n",
    "from unet3d.unet3d_vgg16 import UNet3D_VGG16\n",
    "from utils.Visualization import ImageSliceViewer3D\n",
    "from patchify import patchify\n",
    "import nrrd\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 128/128 [00:01<00:00, 124.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.Size([128, 1, 96, 96, 96]), torch.float32]\n",
      "[torch.Size([128, 5, 96, 96, 96]), torch.float32]\n"
     ]
    }
   ],
   "source": [
    "# Load some data and uniformly sample from it\n",
    "scan, _ = nrrd.read(DATASET_PATH + '/SAIAD 1/scan.nrrd')\n",
    "segm, _ = nrrd.read(DATASET_PATH + '/SAIAD 1/segm.nrrd')\n",
    "\n",
    "#scan_patches = patchify(scan, PATCH_SIZE, step=PATCH_SIZE).reshape(-1,PATCH_SIZE[0],PATCH_SIZE[1], PATCH_SIZE[2])\n",
    "\n",
    "## Random Sampling: Uniform\n",
    "scan_patches = []\n",
    "segm_patches = []\n",
    "side_len = PATCH_SIZE[0]\n",
    "for i in tqdm(range(128)):\n",
    "    # Center coordinates\n",
    "    cx = torch.randint(0,scan.shape[0],(1,))[0]\n",
    "    cy = torch.randint(0,scan.shape[1],(1,))[0]\n",
    "    cz = torch.randint(0,scan.shape[2],(1,))[0]\n",
    "    \n",
    "    #print(f\"Center: {[cx,cy,cz]}\")\n",
    "    bbox_x = [max(cx - side_len//2, 0), min(scan.shape[0], cx+side_len//2)]\n",
    "    bbox_y = [max(cy - side_len//2, 0), min(scan.shape[1], cy+side_len//2)]\n",
    "    bbox_z = [max(cz - side_len//2, 0), min(scan.shape[2], cz+side_len//2)]\n",
    "\n",
    "    # Random patch\n",
    "    pad_x = (-min(cx - side_len//2,0), max(side_len//2 + cx - scan.shape[0], 0))\n",
    "    pad_y = (-min(cy - side_len//2,0), max(side_len//2 + cy - scan.shape[1], 0))\n",
    "    pad_z = (-min(cz - side_len//2,0), max(side_len//2 + cz - scan.shape[2], 0))\n",
    "    \n",
    "    #print([pad_x, pad_y, pad_z])\n",
    "\n",
    "    segm_patch_prepad = segm[bbox_x[0]:bbox_x[1], bbox_y[0]:bbox_y[1], bbox_z[0]:bbox_z[1]]\n",
    "    scan_patch_prepad = scan[bbox_x[0]:bbox_x[1], bbox_y[0]:bbox_y[1], bbox_z[0]:bbox_z[1]]\n",
    "    scan_patch = np.pad(scan_patch_prepad,(pad_x, pad_y, pad_z), 'constant', constant_values=0)\n",
    "    segm_patch = np.pad(segm_patch_prepad,(pad_x, pad_y, pad_z), 'constant', constant_values=0)\n",
    "    \n",
    "    scan_patches.append(scan_patch)\n",
    "    segm_patches.append(segm_patch)\n",
    "    \n",
    "scan_patches = torch.tensor(np.array(scan_patches)).float()\n",
    "scan_patches = torch.unsqueeze(scan_patches,1) # add channel dimension, send to gpu\n",
    "segm_patches = np.array(segm_patches).reshape(-1,PATCH_SIZE[0],PATCH_SIZE[1], PATCH_SIZE[2])\n",
    "segm_patches = one_hot(torch.tensor(segm_patches).to(torch.int64), num_classes=NUM_CLASSES).permute(0,4,1,2,3).float()# put channels first, send to gpu\n",
    "\n",
    "print([scan_patches.shape, scan_patches.dtype])\n",
    "print([segm_patches.shape, segm_patches.dtype])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Work/Users/acharneca/Vessel-Segmentation-pytorch/unet3d/unet3d_vgg16.py:176: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  out = self.softmax(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss Decreased(inf--->0.031945) \t Saving The Model\n",
      "Validation Loss Decreased(0.031945--->0.031413) \t Saving The Model\n",
      "Validation Loss Decreased(0.031413--->0.031326) \t Saving The Model\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     26\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 27\u001b[0m     train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;66;03m#kbar.update(i, values=[(\"loss\", train_loss)])\u001b[39;00m\n\u001b[1;32m     30\u001b[0m valid_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training\n",
    "torch.backends.cudnn.benchmark = True # Speeds up stuff\n",
    "torch.backends.cudnn.enabled = True\n",
    "\n",
    "device = torch.device('cuda')\n",
    "model = UNet3D_VGG16(in_channels=IN_CHANNELS , num_classes= NUM_CLASSES).cuda()\n",
    "criterion = CrossEntropyLoss(weight=torch.Tensor(np.array(CE_WEIGHTS)/np.array(CE_WEIGHTS).sum())).cuda()\n",
    "optimizer = Adam(params=model.parameters())\n",
    "\n",
    "min_valid_loss = math.inf\n",
    "\n",
    "for epoch in range(TRAINING_EPOCH):\n",
    "    # progress bar\n",
    "    #kbar = pkbar.Kbar(target=120, epoch=epoch, num_epochs=TRAINING_EPOCH, width=8, always_stateful=False)\n",
    "\n",
    "    train_loss = 0.0\n",
    "    model.train()\n",
    "    for i in range(0,120,TRAIN_BATCH_SIZE):\n",
    "        image, ground_truth = scan_patches[i:i+TRAIN_BATCH_SIZE], segm_patches[i:i+TRAIN_BATCH_SIZE]\n",
    "    \n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        \n",
    "        target = model(image.cuda())\n",
    "        loss = criterion(target, ground_truth.cuda())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        #kbar.update(i, values=[(\"loss\", train_loss)])\n",
    "    \n",
    "    valid_loss = 0.0\n",
    "    model.eval()\n",
    "    for i in range(120,128,TRAIN_BATCH_SIZE):\n",
    "        image, ground_truth = scan_patches[i:i+TRAIN_BATCH_SIZE], segm_patches[i:i+TRAIN_BATCH_SIZE]\n",
    "        target = model(image.cuda())\n",
    "        loss = criterion(target,ground_truth.cuda())\n",
    "        valid_loss += loss.item()\n",
    "    #kbar.update(i, values=[(\"Validation loss\", valid_loss)])\n",
    "\n",
    "        \n",
    "    #writer.add_scalar(\"Loss/Train\", train_loss / 120, epoch)\n",
    "    #writer.add_scalar(\"Loss/Validation\", valid_loss / 8, epoch)\n",
    "    \n",
    "    #print(f'Epoch {epoch+1} \\t\\t Training Loss: {train_loss / 8} \\t\\t Validation Loss: {valid_loss / 8}')\n",
    "    \n",
    "    if min_valid_loss > valid_loss:\n",
    "        print(f'Validation Loss Decreased({min_valid_loss:.6f}--->{valid_loss:.6f}) \\t Saving The Model')\n",
    "        min_valid_loss = valid_loss\n",
    "        # Saving State Dict\n",
    "        torch.save(model.state_dict(), f'checkpoints/test_epoch{epoch}_valLoss{min_valid_loss}.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecc14554b9674e3f83c8d8d737efab1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(RadioButtons(description='Slice plane selection:', options=('x-y', 'y-z', 'z-x'), style=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<utils.Visualization.ImageSliceViewer3D at 0x147d9c702d60>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.Visualization import ImageSliceViewer3D\n",
    "n=1\n",
    "pred = model(scan_patches[n:n+1].cuda())\n",
    "pred.size()\n",
    "pred_index = np.array(torch.argmax(pred[0].cpu(), dim=0))\n",
    "ImageSliceViewer3D(pred_index, np.array(scan_patches[n:n+1][0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "408474e222884cd9af5176acd2ba14f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(RadioButtons(description='Slice plane selection:', options=('x-y', 'y-z', 'z-x'), style=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<utils.Visualization.ImageSliceViewer3D at 0x1494635c47c0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n=1\n",
    "ImageSliceViewer3D(np.array(segm_patches[n:n+1][0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(scan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 36 125  77  99  75  91  95 110  57 102  11 111  80  97  40  17 126  53\n",
      "   2  54  30 123 116  28  23  93  81  88  49  46  96  62  90 124  61   3\n",
      "   7  86  34   6  55  84 109   9  20   5  78  67 112  64  25  44  10  92\n",
      "  66  98 108  59  41  50  24  63 117  76 104 120  56   8  26  43  33  37\n",
      "  89   4 106  14   1  35 107 114   0  45  94  69 100  83  18  60  12 119\n",
      "  70  51  31  87  16  22 115  13  38 127  42  68  74 118 103 121 101 122\n",
      "  15  19  85  73  58  29  21  52 105  39  82  79  47  71 113  72  48  65\n",
      "  27  32]\n"
     ]
    }
   ],
   "source": [
    "idx = np.arange(128)\n",
    "np.random.shuffle(idx)\n",
    "print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv3d-1       [-1, 32, 96, 96, 96]             896\n",
      "       BatchNorm3d-2       [-1, 32, 96, 96, 96]              64\n",
      "              ReLU-3       [-1, 32, 96, 96, 96]               0\n",
      "            Conv3d-4       [-1, 64, 96, 96, 96]          55,360\n",
      "       BatchNorm3d-5       [-1, 64, 96, 96, 96]             128\n",
      "              ReLU-6       [-1, 64, 96, 96, 96]               0\n",
      "         MaxPool3d-7       [-1, 64, 48, 48, 48]               0\n",
      "       Conv3DBlock-8  [[-1, 64, 48, 48, 48], [-1, 64, 96, 96, 96]]               0\n",
      "            Conv3d-9       [-1, 64, 48, 48, 48]         110,656\n",
      "      BatchNorm3d-10       [-1, 64, 48, 48, 48]             128\n",
      "             ReLU-11       [-1, 64, 48, 48, 48]               0\n",
      "           Conv3d-12      [-1, 128, 48, 48, 48]         221,312\n",
      "      BatchNorm3d-13      [-1, 128, 48, 48, 48]             256\n",
      "             ReLU-14      [-1, 128, 48, 48, 48]               0\n",
      "        MaxPool3d-15      [-1, 128, 24, 24, 24]               0\n",
      "      Conv3DBlock-16  [[-1, 128, 24, 24, 24], [-1, 128, 48, 48, 48]]               0\n",
      "           Conv3d-17      [-1, 128, 24, 24, 24]         442,496\n",
      "      BatchNorm3d-18      [-1, 128, 24, 24, 24]             256\n",
      "             ReLU-19      [-1, 128, 24, 24, 24]               0\n",
      "           Conv3d-20      [-1, 256, 24, 24, 24]         884,992\n",
      "      BatchNorm3d-21      [-1, 256, 24, 24, 24]             512\n",
      "             ReLU-22      [-1, 256, 24, 24, 24]               0\n",
      "        MaxPool3d-23      [-1, 256, 12, 12, 12]               0\n",
      "      Conv3DBlock-24  [[-1, 256, 12, 12, 12], [-1, 256, 24, 24, 24]]               0\n",
      "           Conv3d-25      [-1, 256, 12, 12, 12]       1,769,728\n",
      "      BatchNorm3d-26      [-1, 256, 12, 12, 12]             512\n",
      "             ReLU-27      [-1, 256, 12, 12, 12]               0\n",
      "           Conv3d-28      [-1, 512, 12, 12, 12]       3,539,456\n",
      "      BatchNorm3d-29      [-1, 512, 12, 12, 12]           1,024\n",
      "             ReLU-30      [-1, 512, 12, 12, 12]               0\n",
      "      Conv3DBlock-31  [[-1, 512, 12, 12, 12], [-1, 512, 12, 12, 12]]               0\n",
      "  ConvTranspose3d-32      [-1, 512, 24, 24, 24]       2,097,664\n",
      "           Conv3d-33      [-1, 256, 24, 24, 24]       5,308,672\n",
      "      BatchNorm3d-34      [-1, 256, 24, 24, 24]             512\n",
      "             ReLU-35      [-1, 256, 24, 24, 24]               0\n",
      "           Conv3d-36      [-1, 256, 24, 24, 24]       1,769,728\n",
      "      BatchNorm3d-37      [-1, 256, 24, 24, 24]             512\n",
      "             ReLU-38      [-1, 256, 24, 24, 24]               0\n",
      "    UpConv3DBlock-39      [-1, 256, 24, 24, 24]               0\n",
      "  ConvTranspose3d-40      [-1, 256, 48, 48, 48]         524,544\n",
      "           Conv3d-41      [-1, 128, 48, 48, 48]       1,327,232\n",
      "      BatchNorm3d-42      [-1, 128, 48, 48, 48]             256\n",
      "             ReLU-43      [-1, 128, 48, 48, 48]               0\n",
      "           Conv3d-44      [-1, 128, 48, 48, 48]         442,496\n",
      "      BatchNorm3d-45      [-1, 128, 48, 48, 48]             256\n",
      "             ReLU-46      [-1, 128, 48, 48, 48]               0\n",
      "    UpConv3DBlock-47      [-1, 128, 48, 48, 48]               0\n",
      "  ConvTranspose3d-48      [-1, 128, 96, 96, 96]         131,200\n",
      "           Conv3d-49       [-1, 64, 96, 96, 96]         331,840\n",
      "      BatchNorm3d-50       [-1, 64, 96, 96, 96]             128\n",
      "             ReLU-51       [-1, 64, 96, 96, 96]               0\n",
      "           Conv3d-52       [-1, 64, 96, 96, 96]         110,656\n",
      "      BatchNorm3d-53       [-1, 64, 96, 96, 96]             128\n",
      "             ReLU-54       [-1, 64, 96, 96, 96]               0\n",
      "           Conv3d-55        [-1, 5, 96, 96, 96]             325\n",
      "    UpConv3DBlock-56        [-1, 5, 96, 96, 96]               0\n",
      "================================================================\n",
      "Total params: 19,073,925\n",
      "Trainable params: 19,073,925\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 3.38\n",
      "Forward/backward pass size (MB): 3266659104.75\n",
      "Params size (MB): 72.76\n",
      "Estimated Total Size (MB): 3266659180.89\n",
      "----------------------------------------------------------------\n",
      "--- 0.05122971534729004 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "torch.cuda.empty_cache()\n",
    "start_time = time.time()\n",
    "summary(model=model, input_size=(1, 96,96,96), batch_size=-1, device=\"cuda\")\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "32aad0a8508bff835c20a8d47234734688fb62c0cbdf7488c1eae1822cd413fe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
